\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Letter Localization}

\author{\IEEEauthorblockN{Markus K\"ohler}
\IEEEauthorblockA{\textit{University of Konstanz}\\
Konstanz, Germany \\
markus.koehler@uni-konstanz.de}
}

\maketitle

\begin{abstract}
The abstract of this paper.
\end{abstract}

\begin{IEEEkeywords}
letter, localization, SVM, HOG, IoU
\end{IEEEkeywords}

\section{Introduction}

Computer-printed letters can be found everywhere in our cities, e.g. on traffic signs, stores and advertisement posters. The variety of those letters is huge. Although the same letter can appear in different sizes, colors, fonts, text styles and so on, humans are usually very good at locating and classifying them.

\subsection{Goal}

This paper is dedicated to the question how to locate these letters on any input image using Machine Learning. We do not care about classifying these letters afterwards. To keep it more simple, we only want to detect the 62 characters \mbox{0-9, A-Z, a-z}. Although it is true that our detector might also be able to detect some hand-written letters, we restrict our search space to the computer-printed versions of the letters. Another restriction is that we only use rectangular bounding boxes and we do not take into account that a letter may be rotated.

\subsection{Challenges}

In spite of those restrictions from above, there are still some challenges to handle:
\begin{itemize}
\item As mentioned above, there are many properties of the letters themselves which make them differently.
\item The aspect ratio of a letter may also vary, especially, if the perspective of view changes. Then also the letter may also be distorted.
\item The 62 letters have very different shapes and aspect ratios. So it might not be possible only to train one model for all letters in order to get good results.
\item The background of the bounding boxes containing the letter may also vary or even contain parts of other letters.
\end{itemize}
So one way to handle those challenges is to find similarities of letters in all varieties which we can use to extract features on it. In the following chapter, we will do this by using HOG features and image segmentation.

\section{Data}

\subsection{Image selection}

\subsection{Image manipulation}

\subsection{HOG features}

\subsection{Features from image segmentation}

\section{Models}

\subsection{Support Vector Machine (SVM)}

\subsection{Cascade Object Detector}

\section{Evaluation}

\subsection{Non-maximum suppression}

\subsection{Intersection over Union (IoU)}

\section{Framework}

\begin{thebibliography}{00}
\bibitem{b1} T. E. de Campos, B. R. Babu and M. Varma, ``Character recognition in natural images'', In Proceedings of the International Conference on Computer Vision Theory and Applications (VISAPP), Lisbon, Portugal, February 2009. http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/.
\end{thebibliography}

\end{document}
